Project Description

This project implements a Vision Transformer (ViT) model for classifying American Sign Language (ASL) images. The implementation is based on the Hugging Face transformers library, utilizing a pretrained ViT model (google/vit-base-patch16-224-in21k). The goal is to recognize ASL signs using deep learning and achieve high accuracy with a robust training pipeline.

Requirements
Python 3.8 or higher
Required Libraries:
torch
torchvision
transformers
sklearn
Install the required packages using:
pip install torch torchvision transformers scikit-learn

Usage
Run the Script: Execute the main script to start training and evaluation:
python ViT_ASL_Model.py# asl-vit
# asl-vit
